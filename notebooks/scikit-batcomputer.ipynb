{"cells":[{"cell_type":"markdown","source":["## Pandas - Extracting data"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport glob\n\n# Load data from multiple CSV files into one dataframe\ndf = pd.concat([pd.read_csv(f) for f in glob.glob('/dbfs/police-data/2017-*/*.csv')], ignore_index = True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["## Pandas - Encoding & Extending Data"],"metadata":{}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\nenc = LabelEncoder()\n\n# Remove junk\ntry:\n    df = df.drop(['Context'], axis=1)\nexcept:\n    pass\ndf = df.dropna()\n\ndf['Last outcome category_e'] = enc.fit_transform(df['Last outcome category'])\nOutcome_mapping = dict(zip(enc.classes_, range(len(enc.classes_))))\n\n# This maps the various outcomes to 1 or 0, to a \"Caught\" column\ndef mapOutcome(val):\n    if val in [0, 1, 5, 9, 19, 11, 15, 16, 17, 18, 19, 20, 21, 23]:\n        return 1\n    else:\n        return 0\ndf['Caught'] = df['Last outcome category_e'].map(mapOutcome).astype(int)\n\ndf['Falls within_e'] = enc.fit_transform(df['Falls within'])\nFallsWithin_mapping = dict(zip(enc.classes_, range(len(enc.classes_))))\n\ndf['Crime type_e'] = enc.fit_transform(df['Crime type'])\nCrimeType_mapping = dict(zip(enc.classes_, range(len(enc.classes_))))\n\n# Encode month by striping the string\ndf['Month_e'] = df['Month'].str.slice(5).astype(int)\n\n#print(FallsWithin_mapping)\nprint(CrimeType_mapping)\n#print(Outcome_mapping)\n#df.head(20)\n#print(df.shape)\n#df.iloc[:5, 15]\n#df.info()\n\n# Get our training data in NumPy format\ntrain_data = df.values"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{&apos;Drugs&apos;: 3, &apos;Vehicle crime&apos;: 11, &apos;Other theft&apos;: 5, &apos;Theft from the person&apos;: 10, &apos;Burglary&apos;: 1, &apos;Bicycle theft&apos;: 0, &apos;Possession of weapons&apos;: 6, &apos;Robbery&apos;: 8, &apos;Shoplifting&apos;: 9, &apos;Violence and sexual offences&apos;: 12, &apos;Criminal damage and arson&apos;: 2, &apos;Other crime&apos;: 4, &apos;Public order&apos;: 7}\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["## Scikit-learn - Training the model"],"metadata":{}},{"cell_type":"code","source":["#train_data[0:,14]\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Use RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators = 100)\nX = train_data[0:,13:].astype(int)\ny = train_data[0:,12].astype(int)\nmodel = model.fit(X, y)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["## Test"],"metadata":{}},{"cell_type":"code","source":["# Test all forces, with crime 6 = possesion of a weapon\nfor f, fi in FallsWithin_mapping.items():\n    a = model.predict_proba([[fi, 3, 1]])[0]\n    print(f, a[0])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Essex Police 0.770567276999\nCity of London Police 0.78841775459\nHampshire Constabulary 0.733511951824\nDevon &amp; Cornwall Police 0.798876823168\nDyfed-Powys Police 0.827176643473\nNorthumbria Police 0.829691861758\nGreater Manchester Police 0.788936054012\nNorth Yorkshire Police 0.63310354737\nLancashire Constabulary 0.640533821382\nDorset Police 0.62712666009\nGloucestershire Constabulary 0.879407283732\nCumbria Constabulary 0.695059523295\nDerbyshire Constabulary 0.688940906327\nSouth Yorkshire Police 0.802465627272\nThames Valley Police 0.733249719474\nHertfordshire Constabulary 0.824128478792\nSuffolk Constabulary 0.775336402904\nCheshire Constabulary 0.722857198798\nSouth Wales Police 0.571632444504\nCleveland Police 0.786105106078\nMetropolitan Police Service 0.726046442664\nMerseyside Police 0.672814034962\nDurham Constabulary 0.699172212755\nStaffordshire Police 0.490960879521\nLincolnshire Police 0.868830479899\nBedfordshire Police 0.668862099297\nNorth Wales Police 0.778468305007\nWarwickshire Police 0.789656942397\nGwent Police 0.723234241761\nHumberside Police 0.602570151327\nNorthamptonshire Police 0.949896229764\nWest Yorkshire Police 0.539392501757\nSurrey Police 0.689516835175\nWest Midlands Police 0.799335035958\nNottinghamshire Police 0.841216748202\nLeicestershire Police 0.658475460555\nCambridgeshire Constabulary 0.880673588585\nKent Police 0.541934525921\nWest Mercia Police 0.788358862376\nAvon and Somerset Constabulary 0.884250585177\nSussex Police 0.794715536914\nNorfolk Constabulary 0.823859637492\nWiltshire Police 0.882728943661\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["## Pickle model and store in Azure storage"],"metadata":{}},{"cell_type":"code","source":["#\n# Widgets are how we get values passed from a DataBricks job\n#\ntry:\n  #dbutils.widgets.text(\"model_version\", \"1.0.0\")\n  #dbutils.widgets.text(\"storage_account\", \"modelreg\")\n  #dbutils.widgets.text(\"model_name\", \"batcomputer\")\n\n  # Model version, name & storage-account is passed into job, and storage key is kept in Azure Key Vault\n  STORAGE_KEY       = dbutils.secrets.get(\"ai-deploy-secrets\", \"storage-key\")\n  STORAGE_ACCOUNT   = dbutils.widgets.get(\"storage_account\")\n  MODEL_VERSION     = dbutils.widgets.get(\"model_version\")\n  STORAGE_CONTAINER = dbutils.widgets.get(\"model_name\")\nexcept:\n    pass\n    \n#\n# STORAGE_ACCOUNT value should only be set when this Notebook is invoked via a job\n# So we only pickle and store in Azure blobs when running as a job\n#\nif 'STORAGE_ACCOUNT' in vars():\n  print(\"Saving pickles to:\", STORAGE_ACCOUNT, \" / \", STORAGE_CONTAINER)\n  \n  # Create pickles and data lookup \n  from collections import OrderedDict\n  import pickle\n\n  lookup = OrderedDict()\n\n  # ORDER IS IMPORTANT! This is why we use OrderedDict and create entries one by one\n  lookup[\"Force\"] = FallsWithin_mapping\n  lookup[\"Crime\"] = CrimeType_mapping\n\n  # Create output lookup\n  flags = [\"getaway_proba\", \"busted_proba\"]\n\n  # Pickle the whole damn lot\n  with open(\"model.pkl\" , 'wb') as file:  \n    pickle.dump(model, file)\n    file.close()\n\n  with open(\"lookup.pkl\" , 'wb') as file:  \n    pickle.dump(lookup, file)\n    file.close()\n\n  with open(\"flags.pkl\" , 'wb') as file:  \n    pickle.dump(flags, file)    \n    file.close()\n\n  from azure.storage.blob import BlockBlobService\n\n  # Create the BlockBlockService that is used to call the Blob service for the storage account\n  block_blob_service = BlockBlobService(account_name=STORAGE_ACCOUNT, account_key=STORAGE_KEY) \n\n  # Create a container\n  block_blob_service.create_container(STORAGE_CONTAINER) \n\n  # Upload the created file, use local_file_name for the blob name\n  block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/model.pkl\", \"model.pkl\")\n  block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/lookup.pkl\", \"lookup.pkl\")\n  block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/flags.pkl\", \"flags.pkl\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.7","nbconvert_exporter":"python","file_extension":".py"},"name":"scikit-batcomputer","notebookId":4144178859070218},"nbformat":4,"nbformat_minor":0}
