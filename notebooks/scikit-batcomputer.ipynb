{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Default values when not provided/overridden by job\n",
    "#dbutils.widgets.text(\"model_version\", \"1.0.0\")\n",
    "#dbutils.widgets.text(\"storage_account\", \"modelreg\")\n",
    "#dbutils.widgets.text(\"model_name\", \"batcomputer\")\n",
    "\n",
    "# Model version, name & storage-account is passed into job, and storage key is kept in Azure Key Vault\n",
    "STORAGE_KEY       = dbutils.secrets.get(\"ai-deploy-secrets\", \"storage-key\")\n",
    "STORAGE_ACCOUNT   = dbutils.widgets.get(\"storage_account\")\n",
    "MODEL_VERSION     = dbutils.widgets.get(\"model_version\")\n",
    "STORAGE_CONTAINER = dbutils.widgets.get(\"model_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from CSV\n",
    "df = pd.read_csv('../data/prc-outcomes-open-data-aprjun2018-tables.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Encoding & Extending Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arson': 0, 'Bicycle theft': 1, 'Criminal damage': 2, 'Domestic burglary': 3, 'Fraud offences to 2012/13': 4, 'Harassment': 5, 'Homicide': 6, 'Miscellaneous crimes': 7, 'Non-domestic burglary': 8, 'Other sexual offences': 9, 'Other theft offences': 10, 'Possession of drugs': 11, 'Possession of weapons offences': 12, 'Public order offences': 13, 'Rape': 14, 'Robbery': 15, 'Shoplifting': 16, 'Theft from a vehicle': 17, 'Theft from the person': 18, 'Theft of a motor vehicle': 19, 'Trafficking of drugs': 20, 'Vehicle interference': 21, 'Violence with injury': 22, 'Violence without injury': 23}\n"
     ]
    }
   ],
   "source": [
    "# Extend Prosecuted_E column with mapping of 'Outcome Type'\n",
    "# Outcome Type == 1 is a prosecution, other types we count as \"not prosecuted\"\n",
    "def mapProsecuted(val):\n",
    "    if val == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Prosecuted_E'] = df['Outcome Type'].map(mapProsecuted)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "df['Offence Subgroup_E'] = enc.fit_transform(df['Offence Subgroup'])\n",
    "offence_mapping = dict(zip(enc.classes_, range(len(enc.classes_))))\n",
    "#df.iloc[1930:1990, [2,5,13,14]]\n",
    "#print(offence_mapping)\n",
    "\n",
    "# Get our training data in NumPy format\n",
    "train_data = data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Use RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "model = model.fit(train_data[0:,2:], train_data[0:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">[ 0.99  0.01]\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = model.predict_proba([[3, 42, 0, 0, 2, 1, 1]])\n",
    "\n",
    "print(answer[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle model and other mapping files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create pickles and data lookup \n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "\n",
    "lookup = OrderedDict()\n",
    "\n",
    "# ORDER IS IMPORTANT! This is why we use OrderedDict and create entries one by one\n",
    "lookup[\"Pclass\"] = 0\n",
    "lookup[\"Age\"] = 0\n",
    "lookup[\"SibSp\"] = 0\n",
    "lookup[\"Parch\"] = 0\n",
    "lookup[\"Fare\"] = 0\n",
    "lookup[\"Gender\"] = {\"male\": 1, \"female\": 0}\n",
    "lookup[\"Port\"] = {\"Cherbourg\": 1, \"Southampton\": 2, \"Queenstown\": 3}\n",
    "  \n",
    "# Create output lookup\n",
    "flags = [\"died_proba\", \"survived_proba\"]\n",
    "\n",
    "# Pickle the whole damn lot\n",
    "with open(\"model.pkl\" , 'wb') as file:  \n",
    "    pickle.dump(model, file)\n",
    "    file.close()\n",
    "    \n",
    "with open(\"lookup.pkl\" , 'wb') as file:  \n",
    "    pickle.dump(lookup, file)\n",
    "    file.close()\n",
    "    \n",
    "with open(\"flags.pkl\" , 'wb') as file:  \n",
    "    pickle.dump(flags, file)    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">18</span><span class=\"ansired\">]: </span>&lt;azure.storage.blob.models.ResourceProperties at 0x7fd519806d68&gt;\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install azure-storage\n",
    "from azure.storage.blob import BlockBlobService\n",
    "\n",
    "# Create the BlockBlockService that is used to call the Blob service for the storage account\n",
    "block_blob_service = BlockBlobService(account_name=STORAGE_ACCOUNT, account_key=STORAGE_KEY) \n",
    "\n",
    "# Create a container\n",
    "block_blob_service.create_container(STORAGE_CONTAINER) \n",
    "\n",
    "# Upload the created file, use local_file_name for the blob name\n",
    "block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/model.pkl\", \"model.pkl\")\n",
    "block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/lookup.pkl\", \"lookup.pkl\")\n",
    "block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/flags.pkl\", \"flags.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "scikit-batcomputer",
  "notebookId": 283185785165404
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
