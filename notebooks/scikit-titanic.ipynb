{"cells":[{"cell_type":"markdown","source":["## Pandas - Extracting data"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\n\n# Load data from CSV\ndata = pd.read_csv('/dbfs/FileStore/tables/titanic.csv')"],"metadata":{"trusted":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["## Pandas - Cleaning data"],"metadata":{}},{"cell_type":"code","source":["# Top 10 rows\n#data.head(10)\n\n# Drop rubbish columns\ntry:\n    data = data.drop(['Name', 'Ticket', 'Cabin'], axis=1)\nexcept:\n    pass\n\n# Drop any rows that have nulls/na/blanks\ndata = data.dropna()\n\n# Create numerical columns \ntry:\n    data['Gender'] = data['Sex'].map({'female': 0, 'male':1}).astype(int)\n    data['Port'] = data['Embarked'].map({'C':1, 'S':2, 'Q':3}).astype(int)\n    data = data.drop(['Sex', 'Embarked'], axis=1)\nexcept:\n    pass\n\n# Move survived column first as it's our outcome\ncols = data.columns.tolist()\ncols = [cols[1]] + cols[0:1] + cols[2:]\ndata = data[cols]\n\n# Column info\ndata.info()\n\n# Get our training data in NumPy format\ntrain_data = data.values"],"metadata":{"trusted":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;\nInt64Index: 712 entries, 0 to 890\nData columns (total 9 columns):\nSurvived       712 non-null int64\nPassengerId    712 non-null int64\nPclass         712 non-null int64\nAge            712 non-null float64\nSibSp          712 non-null int64\nParch          712 non-null int64\nFare           712 non-null float64\nGender         712 non-null int64\nPort           712 non-null int64\ndtypes: float64(2), int64(7)\nmemory usage: 55.6 KB\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["## Scikit-learn - Training the model"],"metadata":{}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n\n# Use RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators = 100)\nmodel = model.fit(train_data[0:,2:], train_data[0:,0])"],"metadata":{"trusted":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["## Test"],"metadata":{}},{"cell_type":"code","source":["answer = model.predict_proba([[3, 42, 0, 0, 2, 1, 1]])\n\nprint(answer[0])"],"metadata":{"trusted":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[ 0.99  0.01]\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["## Pickle model and store in Azure storage"],"metadata":{}},{"cell_type":"code","source":["#\n# Widgets are how we get values passed from a DataBricks job\n#\ntry:\n  #dbutils.widgets.text(\"model_version\", \"1.0.0\")\n  #dbutils.widgets.text(\"storage_account\", \"modelreg\")\n  #dbutils.widgets.text(\"model_name\", \"batcomputer\")\n\n  # Model version, name & storage-account is passed into job, and storage key is kept in Azure Key Vault\n  STORAGE_KEY       = dbutils.secrets.get(\"ai-deploy-secrets\", \"storage-key\")\n  STORAGE_ACCOUNT   = dbutils.widgets.get(\"storage_account\")\n  MODEL_VERSION     = dbutils.widgets.get(\"model_version\")\n  STORAGE_CONTAINER = dbutils.widgets.get(\"model_name\")\nexcept:\n    pass\n    \n#\n# STORAGE_ACCOUNT value should only be set when this Notebook is invoked via a job\n# So we only pickle and store in Azure blobs when running as a job\n#\nif 'STORAGE_ACCOUNT' in vars():\n  print(\"Saving pickles to:\", STORAGE_ACCOUNT, \" / \", STORAGE_CONTAINER)\n  \n  # Create pickles and data lookup \n  from collections import OrderedDict\n  import pickle\n\n  lookup = OrderedDict()\n\n  # ORDER IS IMPORTANT! This is why we use OrderedDict and create entries one by one\n  lookup[\"Pclass\"] = 0\n  lookup[\"Age\"] = 0\n  lookup[\"SibSp\"] = 0\n  lookup[\"Parch\"] = 0\n  lookup[\"Fare\"] = 0\n  lookup[\"Gender\"] = {\"male\": 1, \"female\": 0}\n  lookup[\"Port\"] = {\"Cherbourg\": 1, \"Southampton\": 2, \"Queenstown\": 3}\n\n  # Create output lookup\n  flags = [\"died_proba\", \"survived_proba\"]\n\n  # Pickle the whole damn lot\n  with open(\"model.pkl\" , 'wb') as file:  \n    pickle.dump(model, file)\n    file.close()\n\n  with open(\"lookup.pkl\" , 'wb') as file:  \n    pickle.dump(lookup, file)\n    file.close()\n\n  with open(\"flags.pkl\" , 'wb') as file:  \n    pickle.dump(flags, file)    \n    file.close()\n\n  from azure.storage.blob import BlockBlobService\n\n  # Create the BlockBlockService that is used to call the Blob service for the storage account\n  block_blob_service = BlockBlobService(account_name=STORAGE_ACCOUNT, account_key=STORAGE_KEY) \n\n  # Create a container\n  block_blob_service.create_container(STORAGE_CONTAINER) \n\n  # Upload the created file, use local_file_name for the blob name\n  block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/model.pkl\", \"model.pkl\")\n  block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/lookup.pkl\", \"lookup.pkl\")\n  block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/flags.pkl\", \"flags.pkl\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10}],"metadata":{"kernelspec":{"name":"python36","display_name":"Python 3.6","language":"python"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"version":"3","name":"ipython"},"version":"3.6.6","nbconvert_exporter":"python","file_extension":".py"},"name":"scikit-titanic","notebookId":932080253028075},"nbformat":4,"nbformat_minor":0}
