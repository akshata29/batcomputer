{"cells":[{"cell_type":"markdown","source":["## Important Stuff"],"metadata":{}},{"cell_type":"code","source":["# Default values when not provided/overridden by job\n#dbutils.widgets.text(\"model_version\", \"1.0.0\")\n#dbutils.widgets.text(\"storage_account\", \"modelreg\")\n#dbutils.widgets.text(\"model_name\", \"titanic\")\n\n# Model version, name & storage-account is passed into job, and storage key is kept in Azure Key Vault\nSTORAGE_KEY       = dbutils.secrets.get(\"ai-deploy-secrets\", \"storage-key\")\nSTORAGE_ACCOUNT   = dbutils.widgets.get(\"storage_account\")\nMODEL_VERSION     = dbutils.widgets.get(\"model_version\")\nSTORAGE_CONTAINER = dbutils.widgets.get(\"model_name\")"],"metadata":{"trusted":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["## Pandas - Extracting data"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\n\n# Load data from CSV\ndata = pd.read_csv('/dbfs/FileStore/tables/titanic.csv')"],"metadata":{"trusted":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["## Pandas - Cleaning data"],"metadata":{}},{"cell_type":"code","source":["# Top 10 rows\n#data.head(10)\n\n# Drop rubbish columns\ntry:\n    data = data.drop(['Name', 'Ticket', 'Cabin'], axis=1)\nexcept:\n    pass\n\n# Drop any rows that have nulls/na/blanks\ndata = data.dropna()\n\n# Create numerical columns \ntry:\n    data['Gender'] = data['Sex'].map({'female': 0, 'male':1}).astype(int)\n    data['Port'] = data['Embarked'].map({'C':1, 'S':2, 'Q':3}).astype(int)\n    data = data.drop(['Sex', 'Embarked'], axis=1)\nexcept:\n    pass\n\n# Move survived column first as it's our outcome\ncols = data.columns.tolist()\ncols = [cols[1]] + cols[0:1] + cols[2:]\ndata = data[cols]\n\n# Column info\ndata.info()\n\n# Get our training data in NumPy format\ntrain_data = data.values"],"metadata":{"trusted":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;\nInt64Index: 712 entries, 0 to 890\nData columns (total 9 columns):\nSurvived       712 non-null int64\nPassengerId    712 non-null int64\nPclass         712 non-null int64\nAge            712 non-null float64\nSibSp          712 non-null int64\nParch          712 non-null int64\nFare           712 non-null float64\nGender         712 non-null int64\nPort           712 non-null int64\ndtypes: float64(2), int64(7)\nmemory usage: 55.6 KB\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["## Scikit-learn - Training the model"],"metadata":{}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n\n# Use RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators = 100)\nmodel = model.fit(train_data[0:,2:], train_data[0:,0])"],"metadata":{"trusted":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["## Test"],"metadata":{}},{"cell_type":"code","source":["answer = model.predict_proba([[3, 42, 0, 0, 2, 1, 1]])\n\nprint(answer[0])"],"metadata":{"trusted":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[ 0.99  0.01]\n</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["## Pickle model and other mapping files"],"metadata":{}},{"cell_type":"code","source":["# Create pickles and data lookup \nfrom collections import OrderedDict\nimport pickle\n\nlookup = OrderedDict()\n\n# ORDER IS IMPORTANT! This is why we use OrderedDict and create entries one by one\nlookup[\"Pclass\"] = 0\nlookup[\"Age\"] = 0\nlookup[\"SibSp\"] = 0\nlookup[\"Parch\"] = 0\nlookup[\"Fare\"] = 0\nlookup[\"Gender\"] = {\"male\": 1, \"female\": 0}\nlookup[\"Port\"] = {\"Cherbourg\": 1, \"Southampton\": 2, \"Queenstown\": 3}\n  \n# Create output lookup\nflags = [\"died_proba\", \"survived_proba\"]\n\n# Pickle the whole damn lot\nwith open(\"model.pkl\" , 'wb') as file:  \n    pickle.dump(model, file)\n    file.close()\n    \nwith open(\"lookup.pkl\" , 'wb') as file:  \n    pickle.dump(lookup, file)\n    file.close()\n    \nwith open(\"flags.pkl\" , 'wb') as file:  \n    pickle.dump(flags, file)    \n    file.close()"],"metadata":{"trusted":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["#!pip install azure-storage\nfrom azure.storage.blob import BlockBlobService\n\n# Create the BlockBlockService that is used to call the Blob service for the storage account\nblock_blob_service = BlockBlobService(account_name=STORAGE_ACCOUNT, account_key=STORAGE_KEY) \n\n# Create a container\nblock_blob_service.create_container(STORAGE_CONTAINER) \n\n# Upload the created file, use local_file_name for the blob name\nblock_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/model.pkl\", \"model.pkl\")\nblock_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/lookup.pkl\", \"lookup.pkl\")\nblock_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/flags.pkl\", \"flags.pkl\")"],"metadata":{"trusted":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">18</span><span class=\"ansired\">]: </span>&lt;azure.storage.blob.models.ResourceProperties at 0x7fd519806d68&gt;\n</div>"]}}],"execution_count":13}],"metadata":{"kernelspec":{"name":"python36","display_name":"Python 3.6","language":"python"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"version":"3","name":"ipython"},"version":"3.6.6","nbconvert_exporter":"python","file_extension":".py"},"name":"scikit-titanic","notebookId":932080253028075},"nbformat":4,"nbformat_minor":0}
