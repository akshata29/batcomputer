{"cells":[{"cell_type":"markdown","source":["## Load the DataBricks table as Spark DataFrame"],"metadata":{}},{"cell_type":"code","source":["df = spark.table(\"policedata\")\n\ndf = df.drop('FallsWithin')\ndf = df.drop('Lat')\ndf = df.drop('Long')\ndf = df.drop('Context')\ndf = df.drop('Location')\ndf = df.drop('LSOACode')\ndf = df.drop('LSOAName')\ndf = df.drop('CrimeID')\n\ndf = df.na.drop(subset=[\"Outcome\"])\ndf = df.na.drop(subset=[\"ReportedBy\"])\ndf = df.na.drop(subset=[\"Month\"])\n\n# Filter subset (remove when doing full training)\ndf.registerTempTable(\"temp\")\ndf = sqlContext.sql(\"select * from temp where Month = '2017-01'\")\n\nprint(\"Working with\", \"{:,}\".format(df.count()), \"rows\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Working with 353,837 rows\n</div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["## Encoding and feature extraction"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\n\n# Encode the Outcome for our mapping  \nindexer = StringIndexer(inputCol=\"Outcome\", outputCol=\"Outcome_e\")\nindexerModel = indexer.fit(df)\nOutcomeMap = {}\nfor idx, lab in enumerate(indexerModel.labels):\n  OutcomeMap[lab] = idx   \ndf = indexerModel.transform(df)\n\n# !IMPORTANT! This maps outcomes to our caught/not-caught for the crime: 1 = caught, 0 = not caught\n#print(OutcomeMap)\nmapOutcomeUDF = udf(lambda x: 1 if x in [6, 15, 18, 7, 12, 22, 24, 21, 20, 17, 13] else 0, IntegerType())\ndf = df.withColumn(\"y\", mapOutcomeUDF(df.Outcome_e))\n\n# Encode the Crime and ReportedBy columns we'll be training on \nindexer = StringIndexer(inputCol=\"ReportedBy\", outputCol=\"ReportedBy_e\")\nindexerModel = indexer.fit(df)\nReportedByMap = {}\nfor idx, lab in enumerate(indexerModel.labels):\n  ReportedByMap[lab] = idx    \ndf = indexerModel.transform(df)\n\nindexer = StringIndexer(inputCol=\"Crime\", outputCol=\"Crime_e\")\nindexerModel = indexer.fit(df)\nCrimeMap = {}\nfor idx, lab in enumerate(indexerModel.labels):\n  CrimeMap[lab] = idx      \ndf = indexerModel.transform(df)  \n\n# Finally add the month as an integer\nmapMonthUDF = udf(lambda month: int(month[-2:]), IntegerType())\ndf = df.withColumn(\"Month_e\", mapMonthUDF(df.Month))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["## Convert DF to Numpy array"],"metadata":{}},{"cell_type":"code","source":["import numpy as np\ntraining_array = np.array(df.select(\"y\", \"ReportedBy_e\", \"Crime_e\", \"Month_e\").collect())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["## Training the model with Scikit"],"metadata":{}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\n\n# Use RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators = 100)\n#model = BaggingClassifier()\nX = training_array[0:, 1:].astype(int)\ny = training_array[0:, 0].astype(int)\nmodel = model.fit(X, y)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["## Test the model"],"metadata":{}},{"cell_type":"code","source":["print(CrimeMap)\nprint()\n# Test all forces, with crime 12 = possesion of a weapon\nfor f, fi in ReportedByMap.items():\n    a = model.predict_proba([[fi, 12, 1]])[0]\n    print(f, a)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{&apos;Possession of weapons&apos;: 12, &apos;Theft from the person&apos;: 9, &apos;Burglary&apos;: 3, &apos;Other theft&apos;: 2, &apos;Drugs&apos;: 7, &apos;Robbery&apos;: 11, &apos;Violence and sexual offences&apos;: 0, &apos;Vehicle crime&apos;: 4, &apos;Criminal damage and arson&apos;: 1, &apos;Public order&apos;: 6, &apos;Other crime&apos;: 8, &apos;Bicycle theft&apos;: 10, &apos;Shoplifting&apos;: 5}\n\nThames Valley Police [ 0.80341123  0.19658877]\nNorthumbria Police [ 0.74393532  0.25606468]\nDyfed-Powys Police [ 0.63972469  0.36027531]\nNorth Wales Police [ 0.76714786  0.23285214]\nLeicestershire Police [ 0.76868943  0.23131057]\nWest Mercia Police [ 0.70106202  0.29893798]\nLincolnshire Police [ 0.64432676  0.35567324]\nDurham Constabulary [ 0.52467249  0.47532751]\nSouth Yorkshire Police [ 0.86222907  0.13777093]\nCambridgeshire Constabulary [ 0.96678916  0.03321084]\nCity of London Police [ 0.46047619  0.53952381]\nMetropolitan Police Service [ 0.7187991  0.2812009]\nNorfolk Constabulary [ 0.74172757  0.25827243]\nLancashire Constabulary [ 0.88625223  0.11374777]\nGreater Manchester Police [ 0.83939912  0.16060088]\nWest Midlands Police [ 0.86940547  0.13059453]\nKent Police [ 0.53960189  0.46039811]\nEssex Police [ 0.87165128  0.12834872]\nCleveland Police [ 0.75473883  0.24526117]\nHampshire Constabulary [ 0.83316744  0.16683256]\nHumberside Police [ 0.74632645  0.25367355]\nNorth Yorkshire Police [ 0.62191764  0.37808236]\nStaffordshire Police [ 0.78379292  0.21620708]\nDorset Police [ 0.75753059  0.24246941]\nHertfordshire Constabulary [ 0.9285687  0.0714313]\nWiltshire Police [ 0.93365162  0.06634838]\nSuffolk Constabulary [ 0.79232919  0.20767081]\nMerseyside Police [ 0.66320493  0.33679507]\nWarwickshire Police [ 0.73016243  0.26983757]\nGloucestershire Constabulary [ 1.  0.]\nBedfordshire Police [ 0.65252909  0.34747091]\nSouth Wales Police [ 0.56263885  0.43736115]\nCheshire Constabulary [ 0.56587477  0.43412523]\nCumbria Constabulary [ 0.86349938  0.13650062]\nNottinghamshire Police [ 0.85505028  0.14494972]\nGwent Police [ 0.80643192  0.19356808]\nSurrey Police [ 0.69872882  0.30127118]\nSussex Police [ 0.85101676  0.14898324]\nAvon and Somerset Constabulary [ 0.82463743  0.17536257]\nWest Yorkshire Police [ 0.71799799  0.28200201]\nDerbyshire Constabulary [ 0.91265157  0.08734843]\nDevon &amp; Cornwall Police [ 0.68436979  0.31563021]\nNorthamptonshire Police [ 0.97224041  0.02775959]\n</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["## Pickle model and push to Azure storage"],"metadata":{}},{"cell_type":"code","source":["#\n# Widgets are how we get values passed from a DataBricks job\n#\ntry:\n  #dbutils.widgets.text(\"model_version\", \"1.0.0\")\n  #dbutils.widgets.text(\"storage_account\", \"modelreg\")\n  #dbutils.widgets.text(\"model_name\", \"batcomputer\")\n\n  # Model version, name & storage-account is passed into job, and storage key is kept in Azure Key Vault\n  STORAGE_KEY       = dbutils.secrets.get(\"ai-deploy-secrets\", \"storage-key\")\n  STORAGE_ACCOUNT   = dbutils.widgets.get(\"storage_account\")\n  MODEL_VERSION     = dbutils.widgets.get(\"model_version\")\n  STORAGE_CONTAINER = dbutils.widgets.get(\"model_name\")\nexcept:\n    pass\n    \n#\n# STORAGE_ACCOUNT value should only be set when this Notebook is invoked via a job\n# So we only pickle and store in Azure blobs when running as a job\n#\nif 'STORAGE_ACCOUNT' in vars():\n  print(\"Saving pickles to:\", STORAGE_ACCOUNT, \" / \", STORAGE_CONTAINER)\n  \n  # Create pickles and data lookup \n  from collections import OrderedDict\n  import pickle\n\n  lookup = OrderedDict()\n\n  # ORDER IS IMPORTANT! This is why we use OrderedDict and create entries one by one\n  lookup[\"Force\"] = FallsWithin_mapping\n  lookup[\"Crime\"] = CrimeType_mapping\n\n  # Create output lookup\n  flags = [\"getaway_proba\", \"busted_proba\"]\n\n  # Pickle the whole damn lot\n  with open(\"model.pkl\" , 'wb') as file:  \n    pickle.dump(model, file)\n    file.close()\n\n  with open(\"lookup.pkl\" , 'wb') as file:  \n    pickle.dump(lookup, file)\n    file.close()\n\n  with open(\"flags.pkl\" , 'wb') as file:  \n    pickle.dump(flags, file)    \n    file.close()\n\n  from azure.storage.blob import BlockBlobService\n\n  # Create the BlockBlockService that is used to call the Blob service for the storage account\n  block_blob_service = BlockBlobService(account_name=STORAGE_ACCOUNT, account_key=STORAGE_KEY) \n\n  # Create a container\n  block_blob_service.create_container(STORAGE_CONTAINER) \n\n  # Upload the created file, use local_file_name for the blob name\n  block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/model.pkl\", \"model.pkl\")\n  block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/lookup.pkl\", \"lookup.pkl\")\n  block_blob_service.create_blob_from_path(STORAGE_CONTAINER, MODEL_VERSION + \"/flags.pkl\", \"flags.pkl\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.7","nbconvert_exporter":"python","file_extension":".py"},"name":"scikit-batcomputer","notebookId":4144178859070218},"nbformat":4,"nbformat_minor":0}
